source('C:/Users/Sachin/Desktop/data/Day_2.R', echo=TRUE)
mean(data2$Invoice_Amount)
mean(data2$Invoice_Amount)
mean(data2$Invoice_Amount)
median(data2$Invoice_Amount)
min(data2$Invoice_Amount)
max(data2$Invoice_Amount)
var(data2$Invoice_Amount)
sd(data2$Invoice_Amount)
range(data2$Invoice_Amount)
mean(data2$Invoice_Amount)
median(data2$Invoice_Amount)
min(data2$Invoice_Amount)
max(data2$Invoice_Amount)
var(data2$Invoice_Amount)
sd(data2$Invoice_Amount)
range(data2$Invoice_Amount)
str(data2)
class(data2)
levels(data2)
levels(data2$CU_Channel_Partner_Type)
table(data2$CU_Channel_Partner_Type)
str(data2)
class(data2)
table(data2$CU_Channel_Partner_Type)
sd(data2$CU_Channel_Partner_Type)
a <- c(1,2,3,4,-2,9)
a
b <- c ("one","two","three")
b
c <- c(TRUe,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE)
c
c <- c(TRUE,TRUE,TRUE,FALSE,TRUE,TRUE)
c
vec
vec <- c("a","b","c","d","e")
vec
vec[1]
vec[c[1,5]]
vec[c(1,5)]
f<-3
g<-"a"
h<-TRUE
mat
mat <- matrix(c(1,2,3,4),nrow = 2,ncol = 2)
mat
mat1 <- matrix(c(1,2,3,4),nrow = 2,ncol = 2, byrow = TRUE)
mat1
mat[1,]
mat[,2]
mat[2,1]
dim(data2)
data2 <- read.csv("C:/Users/Sachin/Desktop/data/spss dataset.csv")
dim(data2)
x1 <- array(1:24,dim=c(2,4,3))
x1
print(x1[2,,2])
print(x1[,2,3])
print(x1[,,2])
p1<- 1:5
p2<- c(T,F,T,T,T)
L1 <- list(p1,p2)
L1
L1[[1]]
L1[[2]]
vec = c(1:5)
for(val in vec){
print(val)
}
i=1
while(i<6){
print(i)
i++
}
i=1
while(i<6){
print(i)
i=i+1
}
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
mtcars<-mtcars # to view the comp data
View(mtcars)# to view all var in data
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
mtcars<-mtcars # to view the comp data
View(mtcars)# to view all var in data
View(data2)
View(mtcars)
library(dplyr)
library(dplyr)
mtcars<-mtcars
View(mtcars)
View(mtcars)
View(mtcars)
dim(mtcars)
min(mtcars$mpg)
counts <-table(mtcars$gear)
barplot(counts)
barplot(counts,horiz=TRUE)
counts <- table (mtcars$gear)
barplot(counts,
main ="Simple Bar Plot",
xlab = "Improvement",
ylab ="Frequency",
legend = rownames(counts),
col=c("red","yellow","green")
)
barplot(counts,
main ="Gear - Bar Plot",
xlab = "Improvement",
ylab ="Frequency",
legend = rownames(counts),
col=c("red","yellow","green")
)
barplot(counts,
main ="Gear - Bar Plot",
xlab = "Improvement",
ylab ="Frequency",
col=c("red","yellow","green")
)
barplot(counts,
main ="Gear - Bar Plot",
xlab = "Improvement",
ylab ="Frequency",
legend = rownames(counts),
col=c("red","yellow","green")
)
View(mtcars)
View(mtcars)
counts <- table (mtcars$vs,mtcars$gear)
barplot(counts,
main ="car dis by gears and vs",
xlab = "no of gears",
ylab ="Frequency",
legend = rownames(counts),
col=c("grey","green")
)
counts <- table (mtcars$vs,mtcars$gear)
barplot(counts,
main ="car dis by gears and vs",
xlab = "no of gears",
ylab ="Frequency",
legend = rownames(counts),
beside = TRUE,
col=c("grey","green")
)
slices<- c(10,12,4,16,8)
pct<-round(slices/sum(slices)*100)
lbls <-paste (c("us","uk","aus","germany","france"),"",pct,"%",sep="")
pie(slices,labels=lbls,
col=rainbow(5),main="pie chart with percentages")
Slices<- c(10,12,4,16,8)
lbls <- c("us","uk","aus","germany","france")
pie(Slices,labels=lbls,main="simple pie chart")
slices<- c(10,12,4,16,8)
pct<-round(slices/sum(slices)*100)
lbls <-paste (c("us","uk","aus","germany","france"),"",pct,"%",sep="")
pie(slices,labels=lbls,
col=rainbow(5),main="pie chart with percentages")
install.packages("plotrix")
library(plotrix)
install.packages("plotrix")
library(plotrix)
install.packages("plotrix")
library (plotrix)
slices<-c(10,12,4,16,8)
lbls <-paste (c("us","uk","aus","germany","france"),"",pct,"%",sep="")
pie3D(slices,labels=lbls,explode=0.0,main="3D pie chart")
hist(mtcars$mpg ,labels = TRUE)
mtcars$mpg
hist(mtcars$mpg,breaks =8,col ="darkgreen",labels = TRUE)
hist(mtcars$mpg,breaks =10,col ="darkgreen",labels = TRUE)
View(mtcars)
hist(mtcars$mpg,breaks =10,col ="pink",labels = TRUE)
hist(mtcars$mpg,breaks =10,col ="blue",labels = TRUE)
weight<-c(2.5,2.8,3.2,4.8,5.1,5.9,6.8,7.1,7.8,8.1)
months<-c(0,1,2,3,4,5,6,7,8,9)
plot(months,weight,type ="b",main="baby weight chart")
plot(months,weight,type ="s",main="baby weight chart") #s - staircase form of chart
plot(months,weight,type ="o",main="baby weight chart")
plot(months,weight,type ="z",main="baby weight chart")
plot(months,weight,type ="s",main="baby weight chart")
vec <- c(3,2,5,6,4,8,1,2,3,2,4)
summary(vec)
boxplot(vec,varwidth= TRUE)
boxplot(vec,varwidth= TRUE,main = "Box chart")
boxplot(vec,varwidth= TRUE,main = "Box chart", col="red")
plot(mtcars$mpg,mtcars$cyl)
plot(mtcars$mpg,mtcars$disp)
plot(mtcars$mpg,mtcars$cyl)
plot(mtcars$mpg,mtcars$disp)
plot(mtcars$mpg,mtcars$disp ,col="red")
par(mfrow = c(2,2))
plot(mtcars$mpg , type = "l") #displaying as line chart
plot(mtcars$mpg , type = "h")
plot(mtcars$mpg , type = "b")
plot(mtcars$mpg , type = "s")
par(mfrow = c(1,1))
plot(mtcars$mpg , type = "s")
install.packages("corrgram")
library(corrgram)
corrgram(mtcars)
cor(mtcars$disp,mtcars$wt)
cor(mtcars$carb, mtcars$drat)
cor(mtcars$carb, mtcars$am)
cor(mtcars$mpg,mtcars$wt)
m <- matrix(c(1,2,3,4),2,2)
m
apply(m,1,sum) #1 ind it is applied in row
apply(m,1,sum) #1 ind it is applied in row
apply(m,1,sum) #1 ind it is applied in row
apply(m,2,sum) #2 ind it is applied in column
apply(m,2,mean) #1 ind it is applied in row
apply(m,2,min) #1 ind it is applied in row
l= list(a=c(1,1),b=c(2,2),c=c(3,3))
l
lapply(l, sum)
lapply(l, mean)
sapply(l, sum)
l
age = c(22,33,28,21,20,19,34)
gender = c("m","m","m","f","f","f","m")
f = factor(gender)
f = factor(gender)
tapply(age,f,sum)
tapply(age,f,mean)
f
list(rep(1,4),rep(2,3),rep(3,2),rep(4,1))
#or you can do the above list by using mapply as below
mapply(rep,1:4,4:1)
data1 <- read.csv("C:/Users/Sachin/Desktop/data/remission.csv")
View(data1)
summary(data1)
labels(data1)
data1 <- read.csv("C:/Users/Sachin/Desktop/data/remission.csv")
View(data1)
View(data1)
ncol(data1)
nrow(data1)
head(data1)
dim(data1)
str(data1)
data1 <- read.csv("C:/Users/Sachin/Desktop/data/remission.csv", header= TRUE,sep=",")
train_obs <- floor (0.8*nrow (data1))
print(train_obs)
set.seed(200)
train_ind<-sample(seq_len(nrow(data1)),size=train_obs)
test = -train_ind
train_data<-data1[train_ind,]
test_data<-data1[-train_ind,]
testing_high <- data1$Remiss[test]
View(test_data)
regmod<-glm(Remiss~Cell+Smear+Infil+Li+Blast+Temp,data = train_data,family=binomial())
summary(regmod)
prob<-predict(regmod,test_data,type ="response")
prob
prob1<- data.frame(prob)
results <- ifelse(prob1 > 0.5,1,0)
table(results,testing_high) #confusion matrix
misClasificationError <- mean(results != testing_high) #calculating the error rate
misClasificationError
table(testing_high,results)
accuracy <- 1misClasificationError
accuracy <- 1 - misClasificationError
accuracy
getwd()
data1 <- read.csv("C:/Users/Sachin/Desktop/data/churn_data.csv", header= TRUE,sep=",")
data2 <- read.csv("C:/Users/Sachin/Desktop/data/churn_data.csv", header= TRUE,sep=",")
View(data2)
str(data2)
head(data2)
tail(data2)
dim(data2)
nrow(data2)
ncol(data2)
str(data2)
class(data2)
summary(data2)
data3<- data2[,-c(1,2,3)]
library("caTools") #Important package, It helps in splitting the data
#set the seed to reproduce my sample or it will output same output when ever the model is executed
set.seed(2)
sample <- sample.split(data3$churn,SplitRatio=0.70)
sample
trainData <- subset(data3,sample==TRUE)
testData <- subset(data3,sample==FALSE)
library(rpart)
churn_model<- rpart(churn ~ .,data=trainData)
churn_model
library(rattle)
library(rpart.plot)
fancyRpartPlot(churn_model)
pred<- predict(churn_model,testData,type = "class")
pred
pred1<-data.frame(pred)
View(pred1)
#Confusion matrix is a technique for summarizing the performance of a classification algorithm
table(testData$churn ,pred)#create confusion matrix to see how mnay cus are correctly predicted and incorrectly predicted
#% of correct classification :
(1253+155)/(1253+155+35+57) # 94% is the accuracy of our model
churn_model
pred
View(pred1)
#Confusion matrix is a technique for summarizing the performance of a classification algorithm
table(testData$churn ,pred)#create confusion matrix to see how mnay cus are correctly predicted and incorrectly predicted
#% of correct classification :
(1275+161)/(1275+161+13+51) # 94% is the accuracy of our model
install.packages("randomForest")
## RANDOM FOREST CODE STARTS
library(randomForest)
## RANDOM FOREST CODE STARTS
library(randomForest)
random_model = randomForest(churn~.,data=train_data,importance=T)
random_model = randomForest(churn ~ .,data=train_data,importance=T)
data1 <- read.csv("C:/Users/Sachin/Desktop/data/churn_data.csv", header= TRUE,sep=",")
data2 <- read.csv("C:/Users/Sachin/Desktop/data/churn_data.csv", header= TRUE,sep=",")
data3<- data2[,-c(1,2,3)]
library("caTools") #Important package, It helps in splitting the data
#set the seed to reproduce my sample or it will output same output when ever the model is executed
set.seed(2)
sample <- sample.split(data3$churn,SplitRatio=0.70)
sample
trainData <- subset(data3,sample==TRUE)
testData <- subset(data3,sample==FALSE)
library(rpart)
churn_model<- rpart(churn ~ .,data=trainData)
churn_model
## RANDOM FOREST CODE STARTS
# To CREATE RANDOM FOREST
library(randomForest)
random_model = randomForest(churn ~ .,data=train_data,importance=T)
sample <- sample.split(data3$churn,SplitRatio=0.70)
sample
trainData <- subset(data3,sample==TRUE)
testData <- subset(data3,sample==FALSE)
random_model = randomForest(churn ~ .,data=train_data,importance=T)
random_model = randomForest(churn ~ .,data=trainData,importance=T)
random_model
ran_predict = predict(random_model,testData)
ran_predict
table(testData$churn,ran_predict) # Confusion Matrix
ran_predict1 = data.frame(ran_predict)
(1279+158)/(1279+9+54+158)
#% of correct classification :
(1253+155)/(1253+155+35+57) # 94% is the accuracy of our model
(1279+158)/(1279+9+54+158) # 95% is the Accuracy of our model
importance(random_model)
varImpPlot(random_model)
#remove all existing var from r studio
rm(list=ls())
set.seed(1000)
mysample
mysample
mysample
mysample =sample(1:2000)
mysample
summary(mysample)
hist(mysample)
mynorm = rnorm(mysample)
summary(nmynorm)
summary(mynorm)
mynorm = rnorm(1:2000)
summary(mynorm)
hist(mynorm)
mynorm
runif(10)
hist(runif(2000))
hist(runif(5000))
dim(cars)
str(women)
boxplot(women)
cor(women)
plot(women)
abline(lm(weight~height))
attach(women)
abline(lm(weight~height))
cor(women)
detach(women)
fit <- lm(weight ~ height,data=women)
summary(fit)
setwd("C:/Users/Sachin/Desktop/Machine Learning A-Z/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------")
setwd("C:/Users/Sachin/Desktop/Machine Learning A-Z/Part 1 - Data Preprocessing")
dataset = read.csv('Data.csv')
View(dataset)
View(dataset)
View(dataset)
View(dataset)
dataset$Age = ifelse(is,na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x,na.rm = TRUE)),
dataset$Age)
dataset = read.csv('Data.csv')
dataset$Age = ifelse(is,na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
View(dataset)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
View(dataset)
dataset$Country = factor(dataset$Country , levels = c('France','Spain','Germany'),labels = c(1,2,3))
View(dataset)
dataset$Purchased = factor(dataset$Purchased , levels = c('No','Yes'),labels = c(0,1))
View(dataset)
